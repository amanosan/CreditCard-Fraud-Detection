{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split, KFold\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.metrics import roc_auc_score, plot_roc_curve, confusion_matrix\r\n",
    "\r\n",
    "import mlflow\r\n",
    "import mlflow.sklearn\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# data:\r\n",
    "data_path = 'data/creditcard.csv'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(data_path)\r\n",
    "df = df.drop('Time', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We are removing 'Time' column because it was found to add data that isn't very helpful and only adds extra complexity to the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         V1        V2        V3        V4        V5        V6        V7        V8  ...       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  ... -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0\n",
       "1  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102  ...  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0\n",
       "2 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676  ...  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0\n",
       "3 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436  ... -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0\n",
       "4 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  ... -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0\n",
       "\n",
       "[5 rows x 30 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "# normal and anomalies:\r\n",
    "\r\n",
    "normal = df[df.Class == 0].sample(frac=0.5, random_state=2020).reset_index(drop=True)\r\n",
    "anomaly = df[df.Class == 1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(f\"Normal Shape: {normal.shape}\")\r\n",
    "print(f\"Anomaly Shape: {anomaly.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Normal Shape: (142158, 30)\n",
      "Anomaly Shape: (492, 30)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# Splitting the data:\r\n",
    "\r\n",
    "normal_train, normal_test = train_test_split(normal, test_size=0.2, random_state=2020)\r\n",
    "anomaly_train, anomaly_test = train_test_split(anomaly, test_size=0.2, random_state=2020)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "normal_train, normal_validate = train_test_split(normal_train, test_size=0.25, random_state=2020)\r\n",
    "anomaly_train, anomaly_validate = train_test_split(anomaly_train, test_size=0.25, random_state=2020)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "print(f\"{normal_train.shape}, {normal_validate.shape}, {normal_test.shape}\")\r\n",
    "print(f\"{anomaly_train.shape}, {anomaly_validate.shape}, {anomaly_test.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(85294, 30), (28432, 30), (28432, 30)\n",
      "(393, 30), (99, 30), (99, 30)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Now we can create the X y splits:\r\n",
    "\r\n",
    "X_train = pd.concat((normal_train, anomaly_train))\r\n",
    "X_test = pd.concat((normal_test, anomaly_test))\r\n",
    "X_validate = pd.concat((normal_validate, anomaly_validate))\r\n",
    "\r\n",
    "y_train = np.array(X_train['Class'])\r\n",
    "y_test = np.array(X_test['Class'])\r\n",
    "y_validate = np.array(X_validate['Class'])\r\n",
    "\r\n",
    "X_train = X_train.drop('Class', axis=1)\r\n",
    "X_test = X_test.drop('Class', axis=1)\r\n",
    "X_validate = X_validate.drop('Class', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(f\"Training:\\n{X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Testing:\\n{X_test.shape}, {y_test.shape}\")\n",
    "print(f\"Validate:\\n{X_validate.shape}, {y_validate.shape}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training:\n",
      "(85588, 29), (85588,)\n",
      "Testing:\n",
      "(28531, 29), (28531,)\n",
      "Validate:\n",
      "(28531, 29), (28531,)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "# Scaling the data:\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.concat((normal, anomaly)).drop('Class', axis=1))\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_validate = scaler.transform(X_validate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training and Evaluating with MLFlow:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "# function to train:\n",
    "def train_model(model, X_train, y_train):\n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    train_accuracy = model.score(X_train, y_train)\n",
    "    mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "    \n",
    "    print(f\"Train Accuracy: {train_accuracy:.3%}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "# function to evaluate:\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    eval_accuracy = model.score(X_test, y_test)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    auc_score = roc_auc_score(y_test, preds)\n",
    "    \n",
    "    # logging the metrics:\n",
    "    mlflow.log_metric(\"eval_accuracy\", eval_accuracy)\n",
    "    mlflow.log_metric(\"auc_score\", auc_score)\n",
    "    \n",
    "    print(f\"Eval Accuracy: {eval_accuracy:.3%}\")\n",
    "    print(f\"AUC Score: {auc_score:.3%}\")\n",
    "    \n",
    "    # plotting the ROC curve:\n",
    "    roc_curve = plot_roc_curve(model, X_test, y_test, name='ROC Curve')\n",
    "    plt.savefig(\"roc_plot.png\")\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    \n",
    "    # plotting the confusion matrix:\n",
    "    conf_matrix = confusion_matrix(y_test, preds)\n",
    "    ax = sns.heatmap(conf_matrix, annot=True, fmt='g')\n",
    "    ax.invert_xaxis()\n",
    "    ax.invert_yaxis()\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    \n",
    "    # logging these figures:\n",
    "    mlflow.log_artifact(\"roc_plot.png\")\n",
    "    mlflow.log_artifact(\"confusion_matrix.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logging and Viewing MLFlow Runs:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "# creating the model:\n",
    "model = LogisticRegression(random_state=None, max_iter=400, solver='newton-cg')\n",
    "\n",
    "\n",
    "# MLFlow experiment:\n",
    "mlflow.set_experiment('logistic_regression_experiment')\n",
    "with mlflow.start_run():\n",
    "    # training:\n",
    "    train_model(model, X_train, y_train)\n",
    "    \n",
    "    # evaluating:\n",
    "    evaluate_model(model, X_test, y_test)\n",
    "    \n",
    "    # logging:\n",
    "    mlflow.sklearn.log_model(model, 'logistic_regression_model')\n",
    "    \n",
    "    # printing model run info:\n",
    "    print(f\"Model Run: {mlflow.active_run().info.run_uuid}\")\n",
    "    \n",
    "mlflow.end_run()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy: 99.893%\n",
      "Eval Accuracy: 99.874%\n",
      "AUC Score: 85.341%\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model Run: 69e60427c9f143528915eed14945a2cd\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading the Model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "# runs:/RUN_ID/MODEL_NAME\n",
    "loaded_model = mlflow.sklearn.load_model('runs:/69e60427c9f143528915eed14945a2cd/logistic_regression_model')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "print(loaded_model)\n",
    "print(loaded_model.score(X_test, y_test))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LogisticRegression(max_iter=400, solver='newton-cg')\n",
      "0.9987382145736217\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Validation with MLFlow:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "# parameter tuning:\n",
    "\n",
    "anomaly_weights = [ 1, 5, 10, 15]\n",
    "num_folds = 5\n",
    "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=2020)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# broad search experiment:\n",
    "\n",
    "mlflow.set_experiment('logreg_creditcard_broad_search')\n",
    "logs = []\n",
    "\n",
    "for f in range(len(anomaly_weights)):\n",
    "    fold = 1\n",
    "    accuracies = []\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train, test in kfold.split(X_validate, y_validate):\n",
    "        \n",
    "        # starting the mlflow experiment:\n",
    "        with mlflow.start_run():\n",
    "            weight = anomaly_weights[f]\n",
    "            mlflow.log_param(\"anomaly_weight\", weight)\n",
    "            \n",
    "            # defining the class weights\n",
    "            class_weights = {\n",
    "                0: 1, \n",
    "                1: weight\n",
    "            }\n",
    "            \n",
    "            # defining the model\n",
    "            model = LogisticRegression(random_state=None,\n",
    "                                      max_iter=400,\n",
    "                                      solver='newton-cg',\n",
    "                                      class_weight=class_weights).fit(X_validate[train], y_validate[train])\n",
    "            \n",
    "            # printing the metrics:\n",
    "            for _ in range(40):\n",
    "                print(\"-\", end=\"\")\n",
    "            \n",
    "            print(f\"\\nfold {fold}: \\nAnomaly Weight: {weight}\")\n",
    "            \n",
    "            train_accuracy = model.score(X_validate[train], y_validate[train])\n",
    "            mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "            \n",
    "            eval_accuracy = model.score(X_validate[test], y_validate[test])\n",
    "            mlflow.log_metric(\"eval_accuracy\", eval_accuracy)\n",
    "            \n",
    "            preds = model.predict(X_validate[test])\n",
    "            try:\n",
    "                auc_score = roc_auc_score(y_validate[test], preds)\n",
    "            except:\n",
    "                auc_score = -1\n",
    "            \n",
    "            mlflow.log_metric(\"auc_score\", auc_score)\n",
    "            \n",
    "            print(f\"AUC: {auc_score}\\nEval Accuracy:{eval_accuracy}\")\n",
    "            \n",
    "            accuracies.append(eval_accuracy)\n",
    "            auc_scores.append(auc_score)\n",
    "            \n",
    "            log = [model, X_validate[test], y_validate[test], preds]\n",
    "            logs.append(log)\n",
    "            mlflow.sklearn.log_model(model, f\"anomaly_weight_{weight}_fold_{fold}\")\n",
    "            \n",
    "            fold = fold + 1\n",
    "            \n",
    "            # ending the mlflow run:\n",
    "            mlflow.end_run()\n",
    "            \n",
    "    # printing the mean and max metrics:\n",
    "    print(\"Averages:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"AUC: {np.mean(auc_scores)}\")\n",
    "    \n",
    "    print(\"Best:\")\n",
    "    print(f\"Accuracy: {np.max(accuracies)}\")\n",
    "    print(f\"AUC: {np.max(auc_scores)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: 'logreg_creditcard_broad_search' does not exist. Creating a new experiment\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 1\n",
      "AUC: 0.8\n",
      "Eval Accuracy:0.9985982127212195\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 1\n",
      "AUC: 0.8568790049001132\n",
      "Eval Accuracy:0.998422712933754\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 1\n",
      "AUC: 0.8406451922461774\n",
      "Eval Accuracy:0.9982474588152822\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 1\n",
      "AUC: 0.8682452129973255\n",
      "Eval Accuracy:0.9987732211706976\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 1\n",
      "AUC: 0.8528532875621686\n",
      "Eval Accuracy:0.9989484752891693\n",
      "Averages:\n",
      "Accuracy: 0.9985980161860246\n",
      "AUC: 0.8437245395411569\n",
      "Best:\n",
      "Accuracy: 0.9989484752891693\n",
      "AUC: 0.8682452129973255\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 5\n",
      "AUC: 0.8748241603657465\n",
      "Eval Accuracy:0.9987734361310671\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 5\n",
      "AUC: 0.975398919462244\n",
      "Eval Accuracy:0.9982474588152822\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 5\n",
      "AUC: 0.9314663169342972\n",
      "Eval Accuracy:0.9987732211706976\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 5\n",
      "AUC: 0.8943851628367561\n",
      "Eval Accuracy:0.9985979670522257\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 5\n",
      "AUC: 0.8820013855427915\n",
      "Eval Accuracy:0.9985979670522257\n",
      "Averages:\n",
      "Accuracy: 0.9985980100442996\n",
      "AUC: 0.9116151890283671\n",
      "Best:\n",
      "Accuracy: 0.9987734361310671\n",
      "AUC: 0.975398919462244\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9243845612801126\n",
      "Eval Accuracy:0.9982477659015244\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9753109687146626\n",
      "Eval Accuracy:0.9980722046968104\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9313783507133262\n",
      "Eval Accuracy:0.9985979670522257\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.8943851628367561\n",
      "Eval Accuracy:0.9985979670522257\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.8820013855427915\n",
      "Eval Accuracy:0.9985979670522257\n",
      "Averages:\n",
      "Accuracy: 0.9984227743510024\n",
      "AUC: 0.9214920858175297\n",
      "Best:\n",
      "Accuracy: 0.9985979670522257\n",
      "AUC: 0.9753109687146626\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 15\n",
      "AUC: 0.9242966414629858\n",
      "Eval Accuracy:0.9980725424916769\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 15\n",
      "AUC: 0.9751350672194998\n",
      "Eval Accuracy:0.9977216964598669\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 15\n",
      "AUC: 0.9312903844923551\n",
      "Eval Accuracy:0.998422712933754\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 15\n",
      "AUC: 0.8940334835682489\n",
      "Eval Accuracy:0.9978969505783386\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 15\n",
      "AUC: 0.8813861631838532\n",
      "Eval Accuracy:0.9973711882229233\n",
      "Averages:\n",
      "Accuracy: 0.9978970181373118\n",
      "AUC: 0.9212283479853886\n",
      "Best:\n",
      "Accuracy: 0.998422712933754\n",
      "AUC: 0.9751350672194998\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### The best results that we got were from anomaly weights 10 and 15."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# guided search:\n",
    "\n",
    "anomaly_weights = [10, 50, 100, 150, 200]\n",
    "num_folds = 5\n",
    "kfolds = KFold(n_splits=num_folds, shuffle=True, random_state=2020)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# setting up the new experiment:\n",
    "\n",
    "mlflow.set_experiment('logreg_creditcard_guided_search')\n",
    "logs = []\n",
    "\n",
    "for f in range(len(anomaly_weights)):\n",
    "    fold = 1\n",
    "    accuracies = []\n",
    "    auc_scores = []\n",
    "    \n",
    "    for train, test in kfold.split(X_validate, y_validate):\n",
    "        \n",
    "        # starting the mlflow experiment:\n",
    "        with mlflow.start_run():\n",
    "            weight = anomaly_weights[f]\n",
    "            mlflow.log_param(\"anomaly_weight\", weight)\n",
    "            \n",
    "            # defining the class weights\n",
    "            class_weights = {\n",
    "                0: 1, \n",
    "                1: weight\n",
    "            }\n",
    "            \n",
    "            # defining the model\n",
    "            model = LogisticRegression(random_state=None,\n",
    "                                      max_iter=400,\n",
    "                                      solver='newton-cg',\n",
    "                                      class_weight=class_weights).fit(X_validate[train], y_validate[train])\n",
    "            \n",
    "            # printing the metrics:\n",
    "            for _ in range(40):\n",
    "                print(\"-\", end=\"\")\n",
    "            \n",
    "            print(f\"\\nfold {fold}: \\nAnomaly Weight: {weight}\")\n",
    "            \n",
    "            train_accuracy = model.score(X_validate[train], y_validate[train])\n",
    "            mlflow.log_metric(\"train_accuracy\", train_accuracy)\n",
    "            \n",
    "            eval_accuracy = model.score(X_validate[test], y_validate[test])\n",
    "            mlflow.log_metric(\"eval_accuracy\", eval_accuracy)\n",
    "            \n",
    "            preds = model.predict(X_validate[test])\n",
    "            try:\n",
    "                auc_score = roc_auc_score(y_validate[test], preds)\n",
    "            except:\n",
    "                auc_score = -1\n",
    "            \n",
    "            mlflow.log_metric(\"auc_score\", auc_score)\n",
    "            \n",
    "            print(f\"AUC: {auc_score}\\nEval Accuracy:{eval_accuracy}\")\n",
    "            \n",
    "            accuracies.append(eval_accuracy)\n",
    "            auc_scores.append(auc_score)\n",
    "            \n",
    "            log = [model, X_validate[test], y_validate[test], preds]\n",
    "            logs.append(log)\n",
    "            mlflow.sklearn.log_model(model, f\"anomaly_weight_{weight}_fold_{fold}\")\n",
    "            \n",
    "            fold = fold + 1\n",
    "            \n",
    "            # ending the mlflow run:\n",
    "            mlflow.end_run()\n",
    "            \n",
    "    # printing the mean and max metrics:\n",
    "    print(\"Averages:\")\n",
    "    print(f\"Accuracy: {np.mean(accuracies)}\")\n",
    "    print(f\"AUC: {np.mean(auc_scores)}\")\n",
    "    \n",
    "    print(\"Best:\")\n",
    "    print(f\"Accuracy: {np.max(accuracies)}\")\n",
    "    print(f\"AUC: {np.max(auc_scores)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO: 'logreg_creditcard_guided_search' does not exist. Creating a new experiment\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9243845612801126\n",
      "Eval Accuracy:0.9982477659015244\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9753109687146626\n",
      "Eval Accuracy:0.9980722046968104\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.9313783507133262\n",
      "Eval Accuracy:0.9985979670522257\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.8943851628367561\n",
      "Eval Accuracy:0.9985979670522257\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 10\n",
      "AUC: 0.8820013855427915\n",
      "Eval Accuracy:0.9985979670522257\n",
      "Averages:\n",
      "Accuracy: 0.9984227743510024\n",
      "AUC: 0.9214920858175297\n",
      "Best:\n",
      "Accuracy: 0.9985979670522257\n",
      "AUC: 0.9753109687146626\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 50\n",
      "AUC: 0.922626164937577\n",
      "Eval Accuracy:0.9947432977045734\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 50\n",
      "AUC: 0.9734640030154541\n",
      "Eval Accuracy:0.9943918682089029\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 50\n",
      "AUC: 0.9296190262939033\n",
      "Eval Accuracy:0.99509288468279\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 50\n",
      "AUC: 0.9183271172480171\n",
      "Eval Accuracy:0.9940413599719593\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 50\n",
      "AUC: 0.8797162739238779\n",
      "Eval Accuracy:0.9940413599719593\n",
      "Averages:\n",
      "Accuracy: 0.994462154108037\n",
      "AUC: 0.9247505170837659\n",
      "Best:\n",
      "Accuracy: 0.99509288468279\n",
      "AUC: 0.9734640030154541\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 100\n",
      "AUC: 0.9205160893265342\n",
      "Eval Accuracy:0.990537935868232\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 100\n",
      "AUC: 0.9951627088830255\n",
      "Eval Accuracy:0.9903610234840519\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 100\n",
      "AUC: 0.9268920734437976\n",
      "Eval Accuracy:0.9896600070101648\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 100\n",
      "AUC: 0.9429724301962926\n",
      "Eval Accuracy:0.9908867858394672\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 100\n",
      "AUC: 0.8777827179386432\n",
      "Eval Accuracy:0.9901857693655801\n",
      "Averages:\n",
      "Accuracy: 0.9903263043134993\n",
      "AUC: 0.9326652039576586\n",
      "Best:\n",
      "Accuracy: 0.9908867858394672\n",
      "AUC: 0.9951627088830255\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 150\n",
      "AUC: 0.9186697731668719\n",
      "Eval Accuracy:0.9868582442614333\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 150\n",
      "AUC: 0.9927000879507476\n",
      "Eval Accuracy:0.985453908166842\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 150\n",
      "AUC: 0.9247808841404901\n",
      "Eval Accuracy:0.985453908166842\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 150\n",
      "AUC: 0.9411261140366303\n",
      "Eval Accuracy:0.9872064493515598\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 150\n",
      "AUC: 0.9053488155677106\n",
      "Eval Accuracy:0.9866806869961444\n",
      "Averages:\n",
      "Accuracy: 0.9863306393885642\n",
      "AUC: 0.93652513497249\n",
      "Best:\n",
      "Accuracy: 0.9872064493515598\n",
      "AUC: 0.9927000879507476\n",
      "----------------------------------------\n",
      "fold 1: \n",
      "Anomaly Weight: 200\n",
      "AUC: 0.9427026551784772\n",
      "Eval Accuracy:0.9851060101629577\n",
      "----------------------------------------\n",
      "fold 2: \n",
      "Anomaly Weight: 200\n",
      "AUC: 0.9904133685136324\n",
      "Eval Accuracy:0.9808973010865756\n",
      "----------------------------------------\n",
      "fold 3: \n",
      "Anomaly Weight: 200\n",
      "AUC: 0.9226696948371826\n",
      "Eval Accuracy:0.9812478093235191\n",
      "----------------------------------------\n",
      "fold 4: \n",
      "Anomaly Weight: 200\n",
      "AUC: 0.9391039582427143\n",
      "Eval Accuracy:0.9831756046267087\n",
      "----------------------------------------\n",
      "fold 5: \n",
      "Anomaly Weight: 200\n",
      "AUC: 0.9029758150403772\n",
      "Eval Accuracy:0.9819488257974063\n",
      "Averages:\n",
      "Accuracy: 0.9824751101994336\n",
      "AUC: 0.9395730983624768\n",
      "Best:\n",
      "Accuracy: 0.9851060101629577\n",
      "AUC: 0.9904133685136324\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "###### - From the above we see that AUC score increases as we increase the weights from 10 to 15 to 100 to 150 and 200\n",
    "###### - The best AUC score we get is when the anomaly weight is 200."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}